### 感知机

适用于二分类问题

求解办法等价于使用批量大小为1的梯度下降

不能拟合XOR函数，只能产生线性分割面

### 多层感知机

单隐藏层-单分类

**需要非线性的激活函数，否则还是会是单层感知机的效果，隐藏层的输出要经过激活函数**，**最后一层不需要**

常用激活函数：

##### relu：h(x)=max(x,0)   (最常用、简单、运算快)

##### sigmoid：h(x)=1/1+exp(-x)

值域：由于值域刚好落在0~1之间，恰好是概率的范围，因此最常用在二分类模型的输出层

导数：致命缺点，在函数两侧当 x 很小或很大时，导数接近 0（图形呈水平），易出现梯度消失

除了作为二分类中的输出层，**不要用** Sigmoid 激活函数，

h'(x)=h(x)(1-h(x))

##### tanh：h(x)=1-exp(-2x)/1+exp(-2x)

值域：具有数据居中优势，隐藏层出来的激活值平均数接近0，且导数不为 0

(−1,1)

导数：存在和 Sigmoid 一样的缺陷，函数两端导数趋近于 0，也容易出现梯度消失

h'(x)=1-h(x)^2

![](D:\学习笔记\深度学习\L\Snipaste_2023-11-25_14-43-36.png)

多类分类

y1,y2,......yk=softmax(o1,o2,.......ok)

多加了隐藏层

超参数：

1.隐藏层数

2.隐藏层大小（一般依次递减）如果输入维数过高，要慢慢的压缩数据，一次压太多会损失太多信息。



无隐藏层——>一层隐藏层——>多隐藏层