### 神经网络的基本骨架 nn.Module以及卷积的计算

```python
class Model(nn.Module):
    def __init__(self):
        super().__init__()

    def forward(self, input):
        output = input + 1
        return output
```

```python
#卷积计算
input = torch.tensor([[1, 2, 0, 3, 1],
                      [0, 2, 1, 3, 1],
                      [1, 2, 2, 2, 1],
                      [1, 2, 1, 0, 1],
                      [1, 2, 0, 3, 1]])
kernel = torch.tensor([[1, 2, 1],
                       [0, 1, 0],
                       [2, 1, 0]])

input = torch.reshape(input, [1, 1, 5, 5])  # 1表示batch_size,1表示通道数
kernel = torch.reshape(kernel, [1, 1, 3, 3])
print(input.shape)
print(kernel.shape)
# 进行卷积运算
output = F.conv2d(input, kernel, stride=1)
print(output)
output1 = F.conv2d(input, kernel, stride=1, padding=1)  # padding=1表示在输入的每一条边补充一列0
print(output1)
```

卷积实例网站：[conv_arithmetic/README.md at master · vdumoulin/conv_arithmetic (github.com)](https://github.com/vdumoulin/conv_arithmetic/blob/master/README.md)

输出图像宽和高的公式：

![1699792224019](C:\Users\22915\AppData\Local\Temp\1699792224019.png)

padding[0] 通常表示在输入的高度维度上的填充数量，而padding[1]padding[1] 表示在输入的宽度维度上的填充数量

kernel_size[0] 和 kernel_size[1]kernel_size[1] 分别表示卷积核的高度和宽度

dilation[0] 和 dilation[1]dilation[1] 是指沿着高度和宽度方向的膨胀系数。膨胀系数定义了卷积核中元素之间的间隔



### 神经网络池化层的作用：

（图片会变模糊一点）

1. **特征降维：** 最大池化通过选取池化窗口中的最大值来降低每个区域的表示维度。**这有助于减少参数数量，降低计算成本，同时保留最显著的特征**。
2. **平移不变性：** 最大池化提供了一定程度的平移不变性。即在一定范围内的小平移不会显著改变最大值的位置，因此对于一些图像变化，模型能够更好地保持稳定性。
3. **减小过拟合：** **最大池化通过减小每个区域的表示，有助于防止过拟合**。通过降低数据维度，模型更容易泛化到新的样本。
4. **提取主要特征：** **选取每个区域的最大值有助于提取最显著的特征**。这对于图像分类等任务中识别物体的主要特征是很有效的。
5. **计算效率：** 最大池化的计算相对简单，可以有效减小计算量，提高训练和推理的速度。

```python
import torch
from torch import nn

input = torch.tensor([[1, 2, 0, 3, 1],
                      [0, 1, 2, 3, 1],
                      [1, 2, 1, 0, 0],
                      [5, 2, 3, 1, 1],
                      [2, 1, 0, 1, 1]], dtype=torch.float32)
input = torch.reshape(input, (-1, 1, 5, 5))  # -1表示自动计算batch_size
print(input.shape)


class module(nn.Module):
    def __init__(self):
        super().__init__()
        self.pool = nn.MaxPool2d(kernel_size=3, ceil_mode=True)  # ceil_mode=True表示向上取整

    def forward(self, input):
        output = self.pool(input)
        return output


m = module()
output = m(input)
print(output)
```

### 非线性激活

​    非线性激活函数在神经网络中的作用主要体现在引入了非线性变换，使得神经网络能够学习和表示更为复杂的函数关系

1. **引入非线性：** 神经网络的层之间的线性组合如果没有非线性的激活函数，整个网络就会退化成一个线性模型。非线性激活函数引入了非线性变换，使得神经网络能够学习和表示更加复杂的非线性关系。
2. **增加模型表达能力：** 非线性激活函数使得神经网络能够逼近任何复杂的函数，从而提高了模型的表达能力。这是神经网络能够适应各种复杂任务的关键之一。
3. **解决分类问题：** 在分类问题中，非线性激活函数能够引入非线性决策边界，使得神经网络能够更好地划分不同类别。
4. **抑制或增强特征：** 不同的非线性激活函数在特定范围内可以对输入数据的某些部分进行抑制或增强，有助于网络学到更有用的特征。
5. **引入稀疏性：** 一些激活函数，如ReLU，具有稀疏性，即对于负输入直接输出零。这有助于网络学到稀疏的表示，减少参数的冗余性。
6. **梯度传播：** 在反向传播过程中，非线性激活函数能够将误差有效地反向传播到网络的每一层，促进网络的训练。

nn.ReLU

![1699796669538](C:\Users\22915\AppData\Local\Temp\1699796669538.png)

nn.sigmoid

![1699797042961](C:\Users\22915\AppData\Local\Temp\1699797042961.png)

### Sequential的使用

![1699865460501](C:\Users\22915\AppData\Local\Temp\1699865460501.png)

```python
import torchvision
import torch
from torch.nn import Conv2d, MaxPool2d, Flatten, Linear, Sequential
from torch.utils.data import DataLoader
from torch import nn


# cifar10的数据集的分类训练过程
class module(nn.Module):
    def __init__(self):
        super().__init__()
        self.model1 = Sequential(
            Conv2d(3, 32, 5, padding=2),  # padding=2是根据公式计算得到的
            MaxPool2d(2),
            Conv2d(32, 32, 5, padding=2),
            MaxPool2d(2),
            Conv2d(32, 64, 5, padding=2),
            MaxPool2d(2),
            Flatten(),
            Linear(1024, 64),
            Linear(64, 10)
        )

    def forward(self, input):
        output = self.model1(input)
        return output
```

### 损失函数和反向传播

常用损失函数：1.计算出实际输出和目标之间的差距 2.为我们更新输出提供一定依据(反向传播) grad

nn.L1Loss()、nn.MSELoss()、nn.CrossEntropyLoss() 

```python
x = torch.tensor([0.1, 0.2, 0.3])
y = torch.tensor([1])  # 代表第二类
x = torch.reshape(x, (1, 3))  # 1代表batch_size,3代表类别数
Loss3 = nn.CrossEntropyLoss()  # 交叉熵损失函数，用于多分类问题
res3 = Loss3(x, y)
print(res3)  
print(-np.log(np.exp(0.2) / (np.exp(0.1) + np.exp(0.2) + np.exp(0.3))))
```

反向传播的作用：

计算损失函数对网络参数的偏导数，然后利用梯度下降等优化算法来更新网络参数，从而降低网络在训练数据上的预测误差。

```python
import torchvision
import torch
from torch.nn import Conv2d, MaxPool2d, Flatten, Linear, Sequential
from torch.utils.data import DataLoader
from torch import nn

# cifar10的数据集的分类训练过程
dataset = torchvision.datasets.CIFAR10(root='./dataset', train=False, transform=torchvision.transforms.ToTensor())
dataloader = DataLoader(dataset, batch_size=1, num_workers=0, drop_last=False)

print(dataset.classes)


class module(nn.Module):
    def __init__(self):
        super().__init__()
        self.model1 = Sequential(
            Conv2d(3, 32, 5, padding=2),  # padding=2是根据公式计算得到的
            MaxPool2d(2),
            Conv2d(32, 32, 5, padding=2),
            MaxPool2d(2),
            Conv2d(32, 64, 5, padding=2),
            MaxPool2d(2),
            Flatten(),
            Linear(1024, 64),
            Linear(64, 10)
        )

    def forward(self, input):
        output = self.model1(input)
        return output


m = module()
loss = nn.CrossEntropyLoss()
optim = torch.optim.SGD(m.parameters(), lr=0.01)
for epoch in range(10):
    running_loss = 0.0
    for data in dataloader:
        imgs, targets = data
        output = m(imgs)
        #  print(output.shape)
        loss_value = loss(output, targets)
        optim.zero_grad()  # 梯度清零
        loss_value.backward()  # 反向传播
        optim.step()  # 更新参数
        running_loss += loss_value
    print(running_loss)
```

模型的保存和读取

保存：

```python
import torchvision
import torch

vgg16 = torchvision.models.vgg16(pretrained=False)
# 保存方式 1 (模型结构+参数)
# 使用方式 1保存在读取时要可以访问到模型的类定义
torch.save(vgg16, './model/vgg16.pth')

# 保存方式 2 (只有参数)
torch.save(vgg16.state_dict(), './model/vgg16_method2.pth')  # 将模型的参数保存下来
```

读取：

```python
import torch
import torchvision

# 读取方式1对应保存方式1
# model = torch.load('./model/vgg16.pth')
# print(model)

# 读取方式2对应保存方式2
model2 = torch.load('./model/vgg16_method2.pth')
# 加载模型方式
vgg16 = torchvision.models.vgg16(pretrained=False)
vgg16.load_state_dict(model2)
print(vgg16)
```

