真正（True Positive , TP）被模型预测为正的正样本； 

假负（False Negative , FN）被模型预测为负的正样本； 

假正（False Positive , FP）被模型预测为正的负样本； 

真负（True Negative , TN）被模型预测为负的负样本。



横坐标为假阳性率（False Positive Rate, FPR）= FP/FP+TN

纵坐标为真阳性率（True Positive Rate, TPR）= TP/TP+FN

![](D:\学习笔记\深度学习\L\Snipaste_2024-09-29_16-58-37.png)

![](D:\学习笔记\深度学习\L\Snipaste_2024-09-29_17-01-09.png)

![Snipaste_2024-09-29_17-01-17](D:\学习笔记\深度学习\L\Snipaste_2024-09-29_17-01-17.png)

**AUC (Area Under Curve)**

被定义为ROC曲线下的面积，取值范围一般在0.5和1之间。使用AUC值作为评价标准是因为很多时候ROC曲线并不能清晰的说明哪个分类器的效果更好，而作为一个数值，对应AUC更大的分类器效果更好。

AUC = 1，是完美分类器，采用这个预测模型时，存在至少一个阈值能得出完美预测。绝大多数预测的场合，不存在完美分类器。

· 0.5 < AUC < 1，优于随机猜测。这个分类器（模型）妥善设定阈值的话，能有预测价值。

· AUC = 0.5，跟随机猜测一样（例：丢铜板），模型没有预测价值。

· AUC < 0.5，比随机猜测还差；但只要总是反预测而行，就优于随机猜测。



**ROC曲线和AUC不依赖于数据集中正负类别的分布，因此即使在类别不平衡的情况下也能有效地评估模型性能**