## 传统卷积神经网络

学到局部稳定的结构，通过局部化卷积核和层次化的堆叠把学习到的卷积堆叠成层次化多尺度的结构模式



### 欧式数据 vs. 非欧式数据：

欧式数据（Euclidean Data）

欧式数据通常指的是在欧几里得空间中的数据，这些数据点之间的距离可以通过标准的欧几里得距离（即直线距离）来度量。以下是欧式数据的一些特点：

1. **维度空间**：数据存在于一个笛卡尔坐标系统中，每个数据点都有明确的坐标值。
2. **距离度量**：数据点之间的距离可以通过欧几里得距离公式计算，即![](D:\学习笔记\深度学习\L\Snipaste_2024-09-30_10-50-52.png) 其中 **a** 和 **b** 是两个数据点，**n** 是维度的数量。
3. **线性结构**：数据的组织和关系可以通过线性代数的方法来描述和处理。
4. **几何解释**：数据点可以在几何上被解释为空间中的点，线，面等。
5. **应用广泛**：在机器学习、统计分析、图像处理等领域中广泛应用。

非欧式数据（Non-Euclidean Data）

非欧式数据则指的是那些不适用于标准欧几里得距离度量的数据，或者数据的分布和结构不遵循欧几里得空间的规则。以下是非欧式数据的一些特点：

1. **复杂结构**：数据可能存在于复杂的几何结构中，如**流形、图、网络**等。
2. **非线性距离**：数据点之间的距离可能需要通过非线性的方式度量，例如在图数据中，两点之间的最短路径可能不是直线。
3. **拓扑性质**：数据的拓扑性质可能比欧几里得距离更重要，例如在拓扑数据分析中。
4. **高维空间**：在高维空间中，数据的分布可能遵循非欧式的规律，如曼哈顿距离或切比雪夫距离。
5. **数据关联性**：数据点之间的关系可能比它们之间的距离更重要，例如在社交网络分析中

### 卷积核性质：

​		平移不变性



## 卷积

一种积分，对原始信号进行卷积操作得到一个更平滑的信号（调制），对原来信号的处理

### 卷积定义的两种方法：

谱方法是空间方法的子集

谱方法：在谱域定义卷积，不是在结点定义，图上信号变为谱域，谱域实现卷积定义再变到空间域

空间方法：在结点域直接定义卷积，结点之间距离不同无法定义大小相同邻域，实现参数共享困难，中心思想：一个结点在邻域结点的加权平均

### 谱方法

![](D:\学习笔记\深度学习\L\Snipaste_2024-09-30_14-38-38.png)



![](D:\学习笔记\深度学习\L\Snipaste_2024-09-30_14-46-38.png)

![Snipaste_2024-09-30_14-50-11](D:\学习笔记\深度学习\L\Snipaste_2024-09-30_14-50-11.png)





![](D:\学习笔记\深度学习\L\Snipaste_2024-09-30_14-53-22.png)

**谱方法的困难：**

1.依赖于拉普拉斯矩阵的特征分解，复杂度很高

2.矩阵相乘时间

3.非locallized，对一个结点的影响不仅来自邻域，还来自其他结点

ChebyNet：

卷积核取值的空间做了约束

![](D:\学习笔记\深度学习\L\Snipaste_2024-10-08_17-23-33.png)

1.不需要特征分解

2.时间复杂度变为O(E)

3.卷积操作只受k条邻域的影响



###  空间方法

![](D:\学习笔记\深度学习\L\Snipaste_2024-10-08_18-29-42.png)

![](D:\学习笔记\深度学习\L\Snipaste_2024-10-08_18-31-38.png)

#### GraphSAGE

以自己为中心，随机选固定个数结点

#### GCN

aggregating information from neighborhood via a normalized Laplacian matrix

#### GAT（Graph Attention Network）

![](D:\学习笔记\深度学习\L\Snipaste_2024-10-08_18-50-55.png)

### Graph Pooling

#### Graph coarsening（图粗化）

图上结点进行聚类->逐渐变少->变成一个超级结点

![](D:\学习笔记\深度学习\L\Snipaste_2024-10-08_19-09-09.png)

可以让网络变小

#### Node selection

选择结点代表网络

![](D:\学习笔记\深度学习\L\Snipaste_2024-10-08_20-23-48.png)

