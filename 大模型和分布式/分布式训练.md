### 数据并行

​	模型规模不大，但数据量很大，可以使用数据并行，每个机器加载同一个模型，各自算各自机器上输入数据的梯度，并对梯度进行汇总更新。

DP：单进程多线程，每个GPU处理一部分输入，然后进行前向传播和反向传播，将所有卡中的梯度进行汇聚(规约)来更新主卡中的模型参数，最后将主卡中的模型参数再次分发到每一块GPU中，进行下一轮循环。

![](D:\学习笔记\大模型和分布式\pictures\Snipaste_2024-07-24_00-14-19.jpg)

DDP：基于多进程多线程实现

![](D:\学习笔记\大模型和分布式\pictures\Snipaste_2024-07-24_00-14-07.jpg)

**sync grads？**

### 模型并行

​	模型规模过大，一张卡存不下，要把模型拆分成多个模块，放到多个机器/卡中，然后每个卡计算这个模型中的一部分。一个模块的输入是另一个模块的输出时需要进行通信。

![](D:\学习笔记\大模型和分布式\pictures\Snipaste_2024-07-23_02-19-46.jpg)

### Parameter Server

PS架构则是定义了一个Parameter server和多个worker。

![](D:\学习笔记\大模型和分布式\pictures\Snipaste_2024-07-23_02-22-57.jpg)

server：

将数据分成等量大小分发到各个卡上，模型也复制到各个卡

前向计算损失和反向计算梯度

更新参数

在下一轮开始时把参数更新到worker上

worker：

载入server分发过来的数据和模型

模型前向计算

### 关注要素

**Checkpoint stalls**：checkpoint的耗费

**Checkpointing frequency**

**Data invariant：**数据一致性

