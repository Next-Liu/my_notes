## 1.假设一个用户账户有100元，现在该用户同时从app端和网页端进行转账，如何使用redis作为分布式锁防止其进行多次转账

基础的在用户维度加锁，发起转账也要去DB做余额校验，同时操作也有个先后顺序，抢到锁的去执行，后来的转的时候肯定就不成功

## 2.同时有100万个请求抢总额为1亿的红包，怎么设计

**1.预加载红包数据到 Redis**

- 在 **Redis** 中存储 **红包总金额和剩余红包数量**

- 采用 **List** 或 **Sorted Set** 结构存储 **未被领取的红包**

- 采用 **HyperLogLog / Bloom Filter** 进行防刷攻击：

  - **初始化 Bloom Filter**

    - 预先分配足够的**位数组（bit array）**，用多个哈希函数映射用户 ID
    - 布隆过滤器本身可以存储在 **Redis（如 RedisBloom）或本地**，支持**亿级数据存储，占用空间极小**

    **用户请求时进行查询**

    - 先通过 **Bloom Filter 判断用户是否存在**
    - **如果用户存在，则直接拦截，防止重复请求**
    - **如果用户不存在，则允许请求，继续后续逻辑**

    **成功领取后写入 Bloom Filter**

    - 用户成功领取红包后，将用户 ID **插入 Bloom Filter**
    - 之后，所有请求都会先检查 Bloom Filter，避免重复抢红包

**2.限流 & 削峰**

- Nginx 限流：单 IP QPS 限制（如 100）
- Redis 令牌桶 / Leaky Bucket 限流，防止恶意刷接口
- Kafka 队列存储抢红包请求，后端异步处理

**3.多线程高并发处理**

- **线程池** 处理请求，避免阻塞
- **Redis+Lua** 脚本实现**原子性扣减**
- **Kafka 消息队列** 进行异步写库，防止数据库崩溃

**数据落库（异步）**

- 抢到红包的用户信息存入 **Kafka**

- 消费者异步写入 MySQL（提高写入吞吐量）

- Redis 与 MySQL 数据 

  最终一致性保证

  - MySQL 崩溃时，可从 Kafka 重新消费补偿

## 3.秒杀场景

因为某种活动产生巨大流量的场景

1.同时到达大量请求

2.不能超卖

3.不能少卖

4.保证发出请求的用户不是黄牛

​	常用做法是限购

​	![](D:\学习笔记\场景题\pictures\Snipaste_2025-03-17_20-44-03.png)

​	限制ip（但是在同一个网络的用户出口是同一个ip而导致误封，可以加上验证码）

### 如何高并发呢？

主要思路是**削峰、限流、异步**

#### **异步**

​	这一步可以通过消息队列来实现，将**抢和购解耦**，还可以很方便地限频，不至于让MySQL过度承压。抢的话使用Redis来做处理，因为Redis处理简单的扣减请求是非常快的，而直接到MySOL是比较力不从心。Redis可是**单机支撑每秒几万的写入**，并且可以做成集群，提高扩展能力的。
我们可以先将**库存名额预加载到Redis，然后在Redis中进行扣减**，扣减成功的再通过消息队列，传递到MySQL做真正的订单生成。

请求量过大时，比如100w/s，调度多个Redis，用Nginx进行负载均衡

#### **拒绝超卖**

​	1.查询库存是否充足

​	2.减少库存，返回结果

但是并发可能会导致第一步判断有库存，实际调用时却没有了，使用Lua脚本

#### **避免少卖**

库存减少了，但是订单没生成

即从Redis查询库存，扣减完，向消息队列发送消息时失败，即要保证Redis库存和消息队列消费的一致性：

第一种，也最简单的方式，在投递MQ失败的情况下，增加渐进式重试;
第二种，重更安全一点，就是在第一种的基础上，将这条消息记录在磁盘上，慢慢重试;